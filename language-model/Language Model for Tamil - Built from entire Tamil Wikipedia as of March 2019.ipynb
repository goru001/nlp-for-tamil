{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0AWt_a15m68f"
   },
   "source": [
    "\n",
    "# Language Model for Tamil - Built from entire Tamil Wikipedia\n",
    "\n",
    "First Draft: Ravi Annaswamy April 6, 2019.\n",
    "\n",
    "\n",
    "## What is a Language Model?\n",
    "\n",
    "What is a Model, first of all? A model is a organized knowledge-store that can help predict what will happen in various situations. \n",
    "\n",
    "Model of the solar system helps  us predict when will Sun rise at a given place on globe on a given day.\n",
    "\n",
    "A language model, similarly helps predict what word will come next in a sequence of words. This is done by the model systematically learning what usually comes in a context. \n",
    "\n",
    "\n",
    "## Why is it needed?\n",
    "\n",
    "Humans interpret what is being said, because they have the mental model of the language. That is how we know that 'dog bites a man' is different from 'man bites a dog'.\n",
    "\n",
    "Understanding speech in a noisy room, finding and fixing spelling mistakes, and grammatical mistakes are immediate obvious uses of a language model. But it goes more than that. ALL OUR COMMUNICATION is noisy and partial statement, and it is made possible because listener fills in the gaps (reads between lines) because of the language and world model he shares with the speaker or writer.\n",
    "\n",
    "## How do we build a language model?\n",
    "\n",
    "Pre-2010 ngram models were the state of the art. An ngram (say a three word phrase) serving as a context and a table showing what all words followed it how many times in a large text, serves as a prediction model.\n",
    "\n",
    "With Deep learning, several breakthroughs happened in this field. \n",
    "\n",
    "First, words are mapped to meaning vectors in a continuous space so generalization becomes vastly easy. \n",
    "\n",
    "Secondly the system can figure out contexts that are optimal and useful.\n",
    "\n",
    "Third, GPU computing, wikipedia, deep learning libraries such as tensorflow, keras, pytorch and fastai have made doing this a piece of cake.\n",
    "\n",
    "As you will see, we can build a state of the art language model for any language in less than four hours, from collecting text, to tokenizer construction to language model. This is a miracle.\n",
    "\n",
    "Also, even though these are termed as language models, they go beyond just figuring out the grammar (syntax), they also recognize patterns in usage, semantics, so they are a model of the world to the extent it can be inferred from the language. This is why recent recognition that language models with very little fine tuning can be used for question answering and other natural language tasks that are not linguistic but real-world tasks.\n",
    "\n",
    "\n",
    "This code is adapted from https://github.com/goru001/nlp-for-hindi/blob/master/language-model/Hindi_Language_Model.ipynb\n",
    "\n",
    "Modifications for tamil:\n",
    "\n",
    "- Chose to use 8000 word vocabulary for Sentence Piece.\n",
    "\n",
    "- Perplexity of ~20 when trained on 120,000 articles.\n",
    "\n",
    "- Updated the text generator section with a slightly better probing function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Get the Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZ9dGP92ej_l"
   },
   "source": [
    "## Step 1. Install fastai Deep Learning Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "yH7WdaZ8ekBo",
    "outputId": "69dec13f-0fde-4175-99a1-abeb9b31c594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Using cached https://files.pythonhosted.org/packages/44/cc/dcc702cf43bb8c908d172e5be156615928f962366a20834c320cbca2b9d0/fastai-1.0.51-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-ml-py3 in /home/ravi_annaswamy/.local/lib/python3.7/site-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (18.0)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: spacy>=2.0.18 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.0.18)\n",
      "Requirement already satisfied, skipping upgrade: numexpr in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.6.8)\n",
      "Requirement already satisfied, skipping upgrade: bottleneck in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: typing in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.6.4)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (5.3.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: fastprogress>=0.1.19 in /home/ravi_annaswamy/.local/lib/python3.7/site-packages (from fastai) (0.1.20)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/anaconda3/lib/python3.7/site-packages (from packaging->fastai) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (6.12.1)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (1.35)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/anaconda3/lib/python3.7/site-packages (from pandas->fastai) (2018.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.6.3)\n",
      "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
      "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
      "Installing collected packages: fastai\n",
      "  Found existing installation: fastai 1.0.50.post1\n",
      "    Uninstalling fastai-1.0.50.post1:\n",
      "      Successfully uninstalled fastai-1.0.50.post1\n",
      "  Rolling back uninstall of fastai\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/opt/anaconda3/lib/python3.7/site-packages/fastai/__init__.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "y8jnu89DnBtB"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B2PX5-Ysmg_Y"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Grnm1xnJnDz4",
    "outputId": "5bc8a832-d82a-4958-e20a-ed2f0b17e2a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.50.post1', '1.0.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Turn on GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zjVLJcJFnGk5"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Get list of text files for training, and create validation subset of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lN60HogbnJvI"
   },
   "outputs": [],
   "source": [
    "path = Path('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the following to tawiki_small if you want to train on all 12000 articles. The small one here is a subset of 40000 articles for quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iR9sJEytnNYX",
    "outputId": "26457d8a-d555-44a1-c5cb-29f2847d51bd"
   },
   "outputs": [],
   "source": [
    "p = path.glob('../corpus/tawiki/tawiki_large/*/*.txt')\n",
    "files = [str(x) for x in p if x.is_file()]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please note: if you want to quick experiment on this data to get a feel for the code, please choose a smaller subset of files.\n",
    " you can modify the following line to choose only 20 of the 447 files.\n",
    " \n",
    " train_files, test_files = train_test_split(files*[:20]*, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VJZRIcK6nbnL"
   },
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(files, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hcDJVUhJny9W",
    "outputId": "e13602d5-ded6-474d-ddf7-4fe2dfddec92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 90)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Lgi8MjMjioRC"
   },
   "outputs": [],
   "source": [
    "def get_article_count(filelist):\n",
    "  AC=0\n",
    "  for f in filelist:\n",
    "    with open(f, encoding='utf-8') as fp:\n",
    "      text=fp.read()\n",
    "      AC+=text.count('<doc id')\n",
    "  return AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IJB5XHB-i6BM",
    "outputId": "87652596-11f9-487f-d56a-6f37d0370811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102126, 25255)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_count(train_files), get_article_count(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Copy files from tamil wiki into train and valid folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ik0ciqcBoGKy",
    "outputId": "bdf913e5-46e3-44dc-d116-2832700c9509"
   },
   "outputs": [],
   "source": [
    "!mkdir TamilWikiDataset\n",
    "!mkdir TamilWikiDataset/train\n",
    "!mkdir TamilWikiDataset/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dkDkZNiOn2YN"
   },
   "outputs": [],
   "source": [
    "# Preparing dataset for fastai\n",
    "for file in train_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(path/'TamilWikiDataset'/'train'/(str(file).split('/')[-1]), \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6dfzJHzNoSff"
   },
   "outputs": [],
   "source": [
    "for file in test_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(path/'TamilWikiDataset'/'valid'/(str(file).split('/')[-1]), \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6201
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hxw6AUsRDoQ8",
    "outputId": "b9250c04-76ef-45b0-9ec7-986d828c2535"
   },
   "outputs": [],
   "source": [
    "#!zip -r train.zip TamilWikiDataset/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1589
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7eLWYQ6BDosd",
    "outputId": "8e4eb8f7-491b-45ab-8473-64aabbb68142"
   },
   "outputs": [],
   "source": [
    "#!zip -r valid.zip TamilWikiDataset/valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. Setup learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Define Tamil Tokenizer by wrapping our SP model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are creating a tokenizer that will use the rules from the sentencepiece model, to split each sentence into its root parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BhdVU9NSmJHp"
   },
   "outputs": [],
   "source": [
    "#class TamilTokenizer(BaseTokenizer):\n",
    "#    def __init__(self, lang:str):\n",
    "#        self.lang = lang\n",
    "#        self.sp = spm.SentencePieceProcessor()\n",
    "#        self.sp.Load(str(\"tamil_spm_8k.model\"))\n",
    "#        \n",
    "#    def tokenizer(self, t:str) -> List[str]:\n",
    "#        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am placing this inside inltk package, to allow inltk to use this tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from inltk.tokenizer import TamilTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V5PFgPbLolhr"
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str('tamil_spm_8k.model'))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5gtnD-okorAR"
   },
   "outputs": [],
   "source": [
    "tamil_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "46wIzsm_pCgk"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=TamilTokenizer, lang='ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8VFukVAipIfj",
    "outputId": "64882e15-85ae-44bc-dda2-97e768f00116"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Create Fast AI Data generator from the train and valid paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "27mkuLLHpOGy"
   },
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'TamilWikiDataset', tokenizer=tokenizer, vocab=tamil_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kIALPhGSpR6i",
    "outputId": "b77406cf-12f2-4c37-e747-135718bd7f81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LJJUt5e7pVHY"
   },
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_tawiki_8k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "sRXTWQA7pXjg",
    "outputId": "59043ec4-fba5-4eb2-905e-4286dc890d23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁c ric k et &lt;unk&gt; ▁a s s o ci ation &lt;unk&gt; ▁s ta d ium ) ▁என்பது ▁ராஜ் கோட் , இந்தியா வில் ▁உள்ள ▁துடுப்பாட்ட ▁அரங்க ம் ▁ஆகும் . ▁இது ▁இது ▁காந்த ேரி ▁துடுப்பாட்ட ▁அரங்க ம் ▁எனவும் ▁ அழைக்கப்படுகிறது ) ▁ , ▁இது ▁குசராத் து ▁மாநிலத்தின் ▁முதல் ▁சூரிய ▁ஆற்றல் ▁அரங்க ம் ▁ஆகும் . ▁நவம்பர் ▁ , ▁2015 ▁இல் ▁இந்த ▁அரங்க ம் ▁உட்பட ▁இந்தியாவில் ▁உள்ள ▁ஆறு ▁புதிய ▁துடுப்பாட்ட ▁அரங்க ு</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁ / ▁ wiki ? curi d = 21 08 22 \" ▁title =\" தமிழ் ▁மொழியில் ▁உள்ள ▁பேச்சு ▁வழக்கில் ▁திரி ந்த ▁தமிழ்ச் ▁சொற்கள் \"&gt; ▁தமிழ் ▁மொழியில் ▁உள்ள ▁பேச்சு ▁வழக்கில் ▁திரி ந்த ▁தமிழ்ச் ▁சொற்கள் ▁தமிழ் ▁மொழியில் ▁உள்ள ▁சில ▁சொற்கள் ▁காலப்போக்கில் ▁பேச்சு ▁வழக்கில் ▁பொருள் ▁திரி ந்து ▁எழுத்துக்கள் ▁திரி ந்து ▁உள்ளன . ▁அவற்றின் ▁தொகுப்பு . ▁&lt; ▁ / ▁ doc &gt; ▁&lt; doc ▁id =\" 21 08 23\" ▁ url =\" https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>சி க் மக ளூர் \"&gt; ▁சி க் மக ளூர் ▁சி க் மக ளூர் ▁(\" &lt;unk&gt; ch ick ma g al ur \") ▁இந்தியாவின் ▁கர்நாடகா ▁மாநிலத்தில் ▁சி க்க ம கள ூ ரு ▁மாவட்டத்தில் ▁அமைந்துள்ள ▁ஒரு ▁நகரம் . ▁குளம் பி க்கு ▁( co ff ee ) ▁புகழ்பெற்ற ▁மு ல்ல யா நகர ி ▁மலைத்தொடர் ▁அடி வார த்தில் ▁சி க் ம ங்கள ூர் ▁அமைந்துள்ளது , ▁இது ▁கர்நாடகா வின் ▁குளம் பி ▁விளை யும் ▁நில</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁1 20 ▁மில்லி ▁ஆம் பியர் ▁வரையிலும் ▁உள்ளது . ▁இவ்விரு ▁மின்னோட்ட ங்களும் ▁தனித்தனி யான வை யான ாலும் ▁ஒன்ற ி ற்க ொன்று ▁தொடர்புடைய ன . ▁இவை களை ▁இணைக்கும் ▁ஒரு ▁காரணி ▁எதிர்மின் ▁முனை க்கரு கில் ▁காணப்படும் ▁இட ▁மின்ன ூட்ட மாகும் ▁(\" s p ace ▁c har ge \") . ▁குழாய ில் ▁இரு மின் ▁முனை களுக்கு முள்ள ▁மின் ▁அழுத்த ▁வேறுபாடு ▁( p . d ) ▁குறைவாக ▁உள்ள போது , ▁இழை யிலிருந்து ▁இலத்திரன் கள்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ங்கள் ▁இடம்பெற்ற ுள்ள ▁ஒரு ▁சம் பிர தா ய ▁மத மாக ▁இருந்தது . ▁இதனால் ▁ஓவிய ம் ▁மற்றும் ▁சிற்பங்கள் ▁உள்ள ▁பட ங்கள் ▁உட்பட்ட ▁மத ப் ▁பொருட்களை ▁உருவாக்கும் ▁ஊக்க ம் ▁உ ண்ட ானது . ▁1930 ▁ களில் ▁ஸ்டா லி னின் ▁சீர்திருத்த க் ▁கருத்து களுக்குப் ▁பிறகு ▁பௌத்த ம் ▁மற்றும் ▁மத குரு ▁நம்பிக்கை கள் ▁மங்கோலிய ▁மக்கள் ▁குடியரச ில் ▁செல்வ ாக்க ிழந்த ன . ▁உட்புற ▁மங்கோலிய ாவில் ▁பாரம்பரிய ▁மத க் கொள் கை கள் ▁பாதிக்கப்பட்ட ு</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vVI3riA8paS3",
    "outputId": "99ca1874-a5a2-4f00-e7e8-89f4531939ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eP2YMhDekDF"
   },
   "source": [
    "## Step 8. Create a LM Learner object and run it once to estimate good learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uFcI91lTvgBV"
   },
   "outputs": [],
   "source": [
    "data_lm = load_data('TamilWikiDataset', 'data_lm_tawiki_8k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y1r5RCuypjsG"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0yybfjejprBU",
    "outputId": "b2a72e5f-23b7-420d-df9f-2f2315c00ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qXYCz5voqodX",
    "outputId": "32a2a937-799f-4813-d970-fa6c77716b48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "OjGZ5zP4qrat",
    "outputId": "9fdd2b83-535e-48fc-86c3-33e841eeb56b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8HPV9//HXZ1ey5UOWZVuSD/nGGGPAGAtzBbAh4SoJmIQWmjxKApSSkoTQkjR55NGkzUlK0iSUX0MoIUebkDbhCDc43DeWMTa+wPgAy5Z1WLYuW+d+fn/sCC+KJC+2dmd39X4+HotmZr+z89ay3o9mvjPfMXdHRETkYCJhBxARkeyggiEiIklRwRARkaSoYIiISFJUMEREJCkqGCIikhQVDBERSYoKhoiIJEUFQ0REkpIXdoDBNGHCBJ8xY0bYMUREssbKlSvr3b0kmbY5VTBmzJhBZWVl2DFERLKGmb2TbFsdkhIRkaSoYIiISFJUMEREJCkqGCIikpSUFQwzu9PMas1sbcKyS81snZnFzKxigHW3mdkbZva6makXW0QkA6RyD+OXwHm9lq0FLgGeTWL9pe5+vLv3W1hERCR9UnZarbs/a2Yzei3bAGBmqdqsiIikSKb2YTjwuJmtNLNrwg4jIpKplq+v4bZnNqdlW5laME5z9xOA84HrzOyM/hqa2TVmVmlmlXV1delLKCKSAR5du4tfv7gtLdvKyILh7juDn7XAvcDiAdre7u4V7l5RUpLU1e0iIjmjrqWdksLhadlWxhUMMxtlZoU908A5xDvLRUSkl7rmHCgYZnYX8BIw18yqzOwqM1tmZlXAKcBDZvZY0HaymT0crFoGPG9mq4FXgYfc/dFU5RQRyWbxglGQlm2l8iypy/t56t4+2u4ELgimtwALUpVLRCRXdMechtYc2MMQEZHU2t3STsxRwRARkYHVNrcDUDJaBUNERAZQ1xIUDO1hiIjIQOqCPYxSFQwRERlIT8HQHoaIiAyorrmdwoI8CvKjadmeCoaISJZK50V7oIIhIpK16prb03aGFKhgiIhkrXSOIwUqGCIiWau2qY3SNA0LAioYIiJZqbW9i9aObu1hiIjIwOrTfNEeqGCIiGSldF+DASoYIiJZqS7N40iBCoaISFaq1R6GiIgko665nWjEGDdqWNq2qYIhIpKF6prbGT9qGNGIpW2bKhgiIlko3RftgQqGiEhWSvc4UqCCISKSlWqb29J6hhSoYIiIZJ1YzKlv6aB0TI4UDDO708xqzWxtwrJLzWydmcXMrGKAdc8zszfN7G0z+0qqMoqIZKM9+zrojnlO7WH8Ejiv17K1wCXAs/2tZGZR4P8B5wNHA5eb2dEpyigiknUO3Ms7fQMPQgoLhrs/CzT0WrbB3d88yKqLgbfdfYu7dwC/Ay5KUUwRkaxT25T+i/YgM/swpgDbE+argmUiIkI440hBZhaMvq5C8X4bm11jZpVmVllXV5fCWCIimaEuhJFqITMLRhUwNWG+HNjZX2N3v93dK9y9oqSkJOXhRETCVtfczshhUUYPz0vrdjOxYKwA5pjZTDMbBlwG3B9yJhGRjBHGRXuQ2tNq7wJeAuaaWZWZXWVmy8ysCjgFeMjMHgvaTjazhwHcvQv4HPAYsAH4P3dfl6qcIiLZJoyL9gBStj/j7pf389S9fbTdCVyQMP8w8HCKoomIZLW65naOLCtM+3Yz8ZCUiIgMIOcOSYmIyOBr6+ymqa2LUhUMEREZSH1Ip9SCCoaISFbpuTXrhBA6vVUwRESySG1TGwBlY9I7jhSoYIiIZJWaYBwpFQwRERlQTVMbeRFj/Khhad+2CoaISBbZ1dRGaeFwIpG+ht1LLRUMEZEsUtvUTmkIh6NABUNEJKvUNLVRluZbs/ZQwRARySLxgqE9DBERGcD+jvhV3ioYIiIyoJoQr8EAFQwRkaxxoGCoD0NERAZQ0xzeRXuggiEikjVqGnVISkREklDT1EZBfoQxBem9l3cPFQwRkSxR09xO2ZgCzNJ/lTeoYIiIZI2apjbKCsM5HAUqGCIiWaOmqY2yIhUMEREZgLsHexjhnFILKSwYZnanmdWa2dqEZePMbLmZbQp+FvezbreZvR487k9VRhGRbNHU1kVbZyy0M6QgtXsYvwTO67XsK8AT7j4HeCKY78t+dz8+eHwshRlFRLJCz532SkO6aA9SWDDc/Vmgodfii4BfBdO/Ai5O1fZFRHLJrqBgTMzRPYy+lLl7NUDws7SfdgVmVmlmL5uZioqIDHlh3pq1RzhXfxzcNHffaWazgCfN7A1339xXQzO7BrgGYNq0aenMKCKSNjW5fEiqHzVmNgkg+FnbVyN33xn83AI8DSzs7wXd/XZ3r3D3ipKSksFPLCKSAWqb2igsyGPksPD+zk93wbgfuCKYvgL4Y+8GZlZsZsOD6QnAacD6tCUUEclAu5raQu2/gNSeVnsX8BIw18yqzOwq4CbgI2a2CfhIMI+ZVZjZHcGq84BKM1sNPAXc5O4qGCIypNU0tYfafwEp7MNw98v7eersPtpWAlcH0y8Cx6Yql4hINqptamPW7PGhZtCV3iIiGS4Wc2qbw9/DUMEQEclwu1s76Ip57vZhiIjI4Aj71qw9VDBERDJcbXPPNRjawxARkQHsagz/Km9QwRARyXjvXeUd4tDmoIIhIpLxapvbmDB6GPnRcL+yVTBERDJcTVM7pSHemrWHCoaISIbb1dgW+hlSoIIhIpLR3J3tDfuYOm5k2FFUMEREMlldSzvN7V3MnDAq7CgqGCIimWxrXSsAs0pGh5xEBUNEJKNtqQ8KhvYwRERkIFvrWxmWF2Hy2BFhR1HBEBHJZFvqWpgxfiTRiIUdRQVDRCSTbalvZdaE8PsvQAVDRCRjdXbHeHf3PmaVhN9/ASoYIiIZa3vDPrpinhGn1IIKhohIxtpanzmn1IIKhohIxtpSlzmn1IIKhohIxtpS30rxyHyKRw0LOwqQ4oJhZneaWa2ZrU1YNs7MlpvZpuBncT/rXhG02WRmV6Qyp4hIJtpS15Ix/ReQ+j2MXwLn9Vr2FeAJd58DPBHMv4+ZjQO+AZwELAa+0V9hERHJVVvrWzOm/wJSXDDc/Vmgodfii4BfBdO/Ai7uY9VzgeXu3uDue4Dl/HnhERHJWc1tndQ2tw+pPYy+lLl7NUDws7SPNlOA7QnzVcEyEZEhYVv9PgBmZ8g1GJBkwTCz2WY2PJheYmZfMLOxKczV1zXw3k+2a8ys0swq6+rqUhhJRCR9ttS3AJlzSi0kv4dxN9BtZkcAPwdmAr89xG3WmNkkgOBnbR9tqoCpCfPlwM6+Xszdb3f3CnevKCkpOcRIIiKZZUtdK2YwLQNunNQj2YIRc/cuYBnwY3e/AZh0iNu8H+g56+kK4I99tHkMOMfMioPO7nOCZSIiQ8KW+lbKi0dQkB8NO8p7ki0YnWZ2OfEv+AeDZfkHW8nM7gJeAuaaWZWZXQXcBHzEzDYBHwnmMbMKM7sDwN0bgG8BK4LHN4NlIiJDwtb6FmZmyKCDPfKSbPcZ4FrgO+6+1cxmAv9zsJXc/fJ+njq7j7aVwNUJ83cCdyaZT0QkZ7g7W+taqZg+Luwo75NUwXD39cAXAIJDRIXuflMqg4mIDFW1ze20dnRnzCi1PZI9S+ppMxsTXFC3GviFmf17aqOJiAxNm+uCM6Qy7JBUsn0YRe7eBFwC/MLdFwEfTl0sEZGhq2eU2pnZuIcB5AWnwP4lBzq9RUQkBdbvbKKwII9JYwrCjvI+yRaMbxI/rXWzu68ws1nAptTFEhEZulZX7eW48iIiGXAf70RJFQx3/727H+funw3mt7j7x1MbTURk6Gnr7GZjdTMLylM5mMahSbbTu9zM7g2GKq8xs7vNrDzV4UREhpr11U10xZzjsrVgAL8gfoX2ZOKDAD4QLBMRkUG0ZvteABZMLQo5yZ9LtmCUuPsv3L0rePwS0MBNIiKDbHVVI6WFw5mYYR3ekHzBqDezT5lZNHh8CtidymAiIkNRvMN7LGaZ1eENyReMK4mfUrsLqAY+QXy4EBERGSSN+zvZUtfK8Rl4OAqSP0vqXXf/mLuXuHupu19M/CI+EREZJGt3NAJkZIc3HN4d9/5h0FKIiAivBx3ex5Vn8R5GPzLvAJuISBZbU7WXGeNHMnbksLCj9OlwCkaft0wVEZFDs6aqMWMPR8FBhjc3s2b6LgwGjEhJIhGRIai2qY3qxjYWTM3SguHuhekKIiIylK2uind4L8jQ/gs4vENSIiIySFZv30s0YsyfrIIhIiIDWF21lyPLChkxLBp2lH6pYIiIhMzdWVPVmLEX7PVQwRARCdn66iYa93eycGpx2FEGpIIhIhKyh9+oJhoxzp5XGnaUAYVSMMzsejNba2brzOyLfTy/xMwazez14PH1MHKKiKSau/PQmmpOnT2e8aOHhx1nQAOeVpsKZnYM8LfAYqADeNTMHnL33rd8fc7dL0x3PhGRdFq3s4ltu/dx7Zmzw45yUGHsYcwDXnb3fe7eBTwDLAshh4hI6B4KDkedM39i2FEOKoyCsRY4w8zGm9lI4AJgah/tTjGz1Wb2iJnN7+/FzOwaM6s0s8q6urpUZRYRGXTuzsNvxA9HjRuVmeNHJUp7wXD3DcD3geXAo8BqoKtXs9eA6e6+APgP4L4BXu92d69w94qSEt0EUESyx7qdTbyzex8XHjcp7ChJCaXT291/7u4nuPsZQAOwqdfzTe7eEkw/DOSb2YQQooqIpMyDa4LDUUdn/uEoCO8sqdLg5zTiN2K6q9fzEy24P6GZLSaeU7eEFZGc0XM46rQjJlCcBYejIISzpAJ3m9l4oBO4zt33mNm1AO5+G/FbwH7WzLqA/cBl7q7h1EUkZ6zd0cS7Dfv43NIjwo6StFAKhruf3sey2xKmbwVuTWsoEZE0evCNneRFjHPml4UdJWm60ltEJATL19VwyuzxGXt3vb6oYIiIpNnW+la21Lfy4XnZs3cBKhgiImn35MZaAM46KrPHjupNBUNEJM2e3FjDnNLRTB03MuwoH4gKhohIGjW3dfLq1gbOyvCRafuigiEikkbPb6qns9s5a64KhoiIDODJjbWMKchj0fTMvllSX1QwRETSJBZznnqzljPnlpIXzb6v3+xLLCKSpdbsaKS+pYOzs+zsqB4qGCIiafLkxloiBmcemZ0ja6tgiIikyZMbazhhWnHWDDbYmwqGiEga1DS1sXZHU1aeTttDBUNEJA1e3FwPwJIjVTBERGQA63c2MSwvwpFlo8OOcshUMERE0mBDdTNHlo3OytNpe2RvchGRLOHubKhuYt7EMWFHOSwqGCIiKVbX0s7u1g7mTVLBEBGRAWyobgZQwRARkYFtqG4CYN6kwpCTHB4VDBGRFNtQ3cSkooKsuh1rX1QwRERSbEN1U9YfjoKQCoaZXW9ma81snZl9sY/nzcxuMbO3zWyNmZ0QRk4RkcPV3tXN5rrWrD8cBSEUDDM7BvhbYDGwALjQzOb0anY+MCd4XAP8NK0hRUQGyaaaFrpjrj2MQzQPeNnd97l7F/AMsKxXm4uAX3vcy8BYM5uU7qAiIofrQId39heMvBC2uRb4jpmNB/YDFwCVvdpMAbYnzFcFy6pTEehf7l9He1fsIK08yVezw41z4JUGeKnEp3q3s14ZEp+395bZ+57vWSc+nbA8aGfBfyIWb9mzznvtE5ZHzIgE6ybOR8ywYDoaSZg2IxIxomZEI/FHXiS+LD9qRCMR8iNGXjRCftTIj0YYlhehIC9KQX6E4XlRRg6Pkp/FV9BK7tpQ3UxBfoQZ40eFHeWwpb1guPsGM/s+sBxoAVYDXb2a9fVV2ec3tpldQ/ywFdOmTTukTE9srKGts/+C4f7+L9J+2x3S1vvfZjJb6t2u92qe0MDfW3bgOU94whPae2I7HHfeaxsL1vP3fib1K6XciPwoY0bkMaYgn0ljRzBj/EimjRvJEaWjOXnWeAryo2FHlCFoQ3UTc8sKiUYG74/JsISxh4G7/xz4OYCZfZf4HkSiKmBqwnw5sLOf17oduB2goqLikL66nvvyWYeymvTiHi8sPQUlFsz3LIu5E4sdmO4Onu+OOd2xYFnwsyvmdHXH57tiMTqD6Y6uGB3dMTq6YrR3xWjr7Kats5t9Hd00t3XStL+Lvfs72Lm3jVXv7qG5Lf63yIj8KGccOYFz50/k7KPKKBqZH+6bJUOCu7NxVxPnzp8YdpRBEUrBMLNSd681s2nAJcApvZrcD3zOzH4HnAQ0untKDkfJ4HnvENQgHpY7HO7O3n2drN3ZyOPranh8/S4eW1dDftQ4Y04JFy6YxIfnlVFYoOIhqVHT1M6efZ050X8BIRUM4O6gD6MTuM7d95jZtQDufhvwMPG+jbeBfcBnQsopWczMKB41jNPnlHD6nBL+9WPzWV21l4ffqOahNdU8sbGWYXkRzpgT3/P48LyyrL0TmmSmXOrwhvAOSZ3ex7LbEqYduC6toSTnRSLGwmnFLJxWzFfPn8eq7Xt4YHU1j6/bxZ821BKNGBXTizntiAmcOns8x5WPZVieOtLl0K0PCsbcidl/DQaEt4chEqpIxFg0fRyLpo/jGx89mrU7mnhs3S6e3FjLj/70Fv++HEYOi3LKrPGcNa+Us44qZVLRiLBjS5bZuKuZKWNHUDQiNw57qmDIkGdmHFtexLHlRdx47lz2tHbwytbdvPD2bp5+q5YnNtYCMH/yGC45oZxlC6cwToeuJAm5MiRIDxUMkV6KRw3jvGMmcd4xk3B33q5t4YmNtTyydhffenA9339kI+fML+OTJ03n5Fnj3ndNi0iP5rZOttS18BfH5s41xyoYIgMwM+aUFTKnrJBrz5zNxl1N/O+K7dy7agcPrqlm4bSxXLfkCM6eV6rCIe+z8p09xBwWzxwXdpRBox49kQ/gqIlj+MZH5/PyV8/m2xcfQ11zO1f/upLzf/IcD62pJhbLkKsYJXSvbm0gL2IsnDY27CiDRgVD5BAU5Ef51MnTeerGJfz7Xy6gszvGdb99jQtueY7H1u163xX2MjSt2NbA/ClFjByWOwdyVDBEDkN+NMIlJ5Tz+A1n8uO/Op72rhh/998r+ditL/Di5vqw40lI2jq7Wb29kZNy6HAUqGCIDIpoxLh44RSW33AGN3/iOBpaO/jr/3qFq365grdrm8OOJ2m2evteOrpjnDhDBUNE+pEXjXBpxVSe+Mcz+cr5R/Hq1gbO/fFz/PN9a2nc3xl2PEmTFdsaADhxRnHISQaXCoZIChTkR7n2zNk88+WlfPKkafzmlXc4+4dPc++qKvVvDAGvbG1gbllh1t/DuzcVDJEUGjdqGN+86Bju/9yHKC8eyQ3/u5rLbn+ZdTsbw44mKdLVHeO1d/Zw4szc2rsAFQyRtDhmShH3fPZUvnfJsbxZ08xf3PI81/9uFe/u3hd2NBlkG6qbae3oZvHM8WFHGXS5c76XSIaLRIzLF0/jgmMn8bNnNnPnC1t5+I1qPnnSdG748JG6R0eOeGXrbgAW51iHN2gPQyTtikbk8+XzjuKZLy3l0oqp/PqlbZz1w6f5feV2XfiXA1Zsa2DquBFMLCoIO8qgU8EQCUnZmAK+u+xYHvj8h5gxYRRf+sMaLv3ZS6zdof6NbOXurNi2h8Uzcu9wFKhgiIRu/uQifv93p3DzJ45jW30rH731eb56zxrqW9rDjiYf0Oa6FhpaO1icgx3eoIIhkhEiEePSiqk8eeMSrjxtJr+vrGLpzU9zx3Nb6OyOhR1PkvTq1j0AOXfBXg8VDJEMUjQin3++8Ggeu+EMKmYU8+2HNnDhLc9TGVwIJpntmbdqKS0czswJo8KOkhIqGCIZaHbJaH7xmcX8199U0NLexSdue4mv3L2GPa0dYUeTfuzd18FTG+v46ILJOTvUvU6rFclgHzm6jFNnj+cnT2zi589v5Z7XdnDizGKWzi1lydwSZpeMztkvp2zz0BvVdHTHWLZwSthRUsZyaZiCiooKr6ysDDuGSEq8uauZe16r4qk3a3mrpgWARdOLuW7pbJbO1Q2cwnbpbS+yZ18ny284I6v+X5jZSnevSKZtKIekzOwGM1tnZmvN7C4zK+j1/KfNrM7MXg8eV4eRUySTzJ1YyFcvmMfjN5zJ8/+0lK9feDS7Gtu48peVXHDL8zyweifduo4jFNsb9rFi2x6WLZySVcXig0p7wTCzKcAXgAp3PwaIApf10fR/3f344HFHWkOKZLjy4pFc+aGZPP2lJfzw0gV0dHXz+btWce6Pn+WPr+9Q4Uiz+1btAOCi4yeHnCS1wur0zgNGmFkeMBLYGVIOkayWH43w8UXlLL/hTG7964VEDK7/3euc86Nn+MPKKto6u8OOmPPcnXtf38HimeMoLx4ZdpyUSnvBcPcdwA+Ad4FqoNHdH++j6cfNbI2Z/cHMpqY1pEiWiUSMC4+bzKPXn8F/fvIE8qMRbvz9ak753hN875ENbG/QIIep8saORrbUteZ0Z3ePMA5JFQMXATOBycAoM/tUr2YPADPc/TjgT8CvBni9a8ys0swq6+rqUhVbJCtEIsYFx07iketP57dXn8RJM8dzx3NbOePmp7jm15Ws2Nag+3EMsnte28GwaIQLjp0UdpSUS/tZUmZ2KXCeu18VzP8NcLK7/30/7aNAg7sXHey1dZaUyJ+rbtzP/7z8Dr955V327utkQXkRf33SNI6dMpbZpaMYnhcNO2LW6uyOcfJ3n2DxzHH89FOLwo5zSD7IWVJhXIfxLnCymY0E9gNnA+/7ljezSe5eHcx+DNiQ3ogiuWNS0Qi+dO5RXLf0CO5+bQd3Pr+Vf7r7DQDyIsasklGcOnsCH10wiYVTi4lEcvcsn8F236od7G7t4JITysOOkhahXIdhZv8K/BXQBawCrga+BlS6+/1m9j3ihaILaAA+6+4bD/a62sMQObhYzNlc18LGXc1s3NXE+p1NvLB5Nx1dMaaMHcEFx06kYsY4FpSPzckhugdLc1snS3/wDFPHjeDua0/N2kL7QfYwdOGeiNDc1smfNtTwwOpqnttUR2d3/HuhtHA4i2eO48LjJrNkbgkF+Tp81eOmRzZy2zObue+60zh+6tiw4xyyTD8kJSIZprAgn2ULy1m2sJy2zm7W7WxiTdVe1lQ18uxbdTy4pprRw/M45+gyLjh2Eh+aM2FIF493drdy5/Nb+fgJ5VldLD4oFQwReZ+C/CiLphezaHr8ng5d3TFe2rKbB1bv5NG1u7hn1Q5GDYty1rwyzp1fxuKZ4ygtHFqHrr7z0Abyo8Y/nTc37ChppYIhIgPKi0Y4fU4Jp88p4dsXH8uLm+t5dO0uHl9fwwOr49fcTh8/kkXTizll1njOnFuS0wXk+U31PL6+hi+fN5fSMbn7e/ZFfRgicki6umOs2dHIym17WLGtgZXv7GF3MPz6/MljWDq3lKVHlXD81GKiWdoh3Ft9Szsf/+mLxNxZfsOZOXFYTp3eIpJ27s766iaefrOOp9+s5bV399Idc8aOzOfMI0tYMreEU2ZNyNozr5raOrnsZy+zpb6F31x9Eoum58Zd9VQwRCR0jfs6eXZTHU+9Wcszb9a9t/cxc8IoTp41jg8dUcKH5kygaER+yEkPrq2zm7/5+aus2r6HO644kTOPLAk70qBRwRCRjBKLxfc+Xt6ym5e3NPDK1t00t3URjRiLphezZG4JZx5ZwtGTxmTc8OCd3TH+7r9X8tSbtdxy2UI+uiC3RqRVwRCRjNbVHWN11V6e2hjfA1m3swmAksLhnD5nAqfOnsCC8iJmlYwOtf9je8M+/vH/VvPqtga+s+wYPnnS9NCypIoKhohkldqmNp7dVM8zb9Xx3KY69u7rBGDUsCjzpxSxoLyI46cWs2BqEVPGjkjLXsh9q3bwz/etxYFvX3wMF+foaLQqGCKStbpjzpa6FtZUNbKmai+rqxpZX91ER1cMiO+FLJ4xjsUz44+5ZYWDNiyHu7PynT3c+cJWHn5jFxXTi/nRXx3P1HG5e58LFQwRySkdXTHe3NXM69v3sPKdPby6tYGdjW0ADM+LMKtkNLNLRjG7ZDRzykYzp7SQGRNGHnQk3o6uGLsa26jau48X3q7nj6/vpGrPfgryI1y35Ag+u2Q2edGw7jOXHioYIpLzqvbs49WtDWyobmJzXStv17awfc8+er7SohGjtHA4eVEjLxIhYuDE92C6Y057V4z6lvb32kcMTjtiAssWTuGc+RMZPXxoXNessaREJOeVF4/8s1uitnV2s6WulU21zbxd20J1YxuxmNMVFAksPqR71Iz8aISJRQVMKR7BlLEjmDuxkAmjh4f022QHFQwRyRkF+VGOnjyGoyePCTtKTsrtg3MiIjJoVDBERCQpKhgiIpIUFQwREUmKCoaIiCRFBUNERJKigiEiIklRwRARkaTk1NAgZtYIbOrjqSKgMcn5num+lk0A6j9grN7bSvb5vpb3lam/6cPJPFCuZPNlS+a+lmfj5yOZzInT+nwk/3yufz7muHtRUmncPWcewO3JLB9ovme6n2WVg5Xpg2buL9PB8h9K5kPNnY2Zc+XzkUzmsN9rfT4y//NxsEeuHZJ6IMnlA80/MMCywcx0sOf7Wt5fpoPlPxSHkjsbM/e1PBs/H8lkTpzW5yP554fS52NAOXVIKtXMrNKTHNUxUyhz+mRjbmVOn2zNnSjX9jBS7fawAxwCZU6fbMytzOmTrbnfoz0MERFJivYwREQkKUO2YJjZnWZWa2ZrD2HdRWb2hpm9bWa3WMId6c3s82b2ppmtM7N/y/TMZvYvZrbDzF4PHhdkeuaE5280MzezCYOX+L3XTsV7/S0zWxO8z4+b2eQsyHyzmW0Mct9rZmOzIPOlwb+/mJkNWp/B4WTt5/WuMLNNweOKhOUDfu5DdSinp+XCAzgDOAFYewjrvgqcAhjwCHB+sHwp8CdgeDBfmgWZ/wW4MZve5+C5qcBjwDvAhGzIDYxJaPMF4LYsyHwOkBdMfx/4fhZkngfMBZ4GKsLOGuSY0WvZOGBL8LM4mC4e6PfKhMeQ3cNw92eBhsRlZjbbzB41s5Vm9pyZHdV7PTObRPwf/kse/7/7a+Di4OnPAjcA1xT0AAAF4UlEQVS5e3uwjdosyJxSKcz8I+DLxG/TnBW53b0poemowc6eosyPu3tX0PRloDwLMm9w9zcHM+fhZO3HucByd29w9z3AcuC8MP+tJmPIFox+3A583t0XATcC/9lHmylAVcJ8VbAM4EjgdDN7xcyeMbMTU5o27nAzA3wuOORwp5kVpy7qew4rs5l9DNjh7qtTHbSXw36vzew7ZrYd+CTw9RRm7TEYn48eVxL/izfVBjNzqiWTtS9TgO0J8z35M+X36pPu6R0ws9HAqcDvEw4Z9nVH+L6OJ/b8pZhHfPfyZOBE4P/MbFbwl8KgG6TMPwW+Fcx/C/gh8S+GlDjczGY2Evga8UMlaTNI7zXu/jXga2b2VeBzwDcGOeqBIIOUOXitrwFdwG8GM+OfBRnEzKk2UFYz+wxwfbDsCOBhM+sAtrr7MvrPH/rvNRAVjAMiwF53Pz5xoZlFgZXB7P3Ev2ATd8vLgZ3BdBVwT1AgXjWzGPHxY+oyNbO71ySs91/AgynK2uNwM88GZgKrg3+k5cBrZrbY3XdlcO7efgs8RAoLBoOUOeiQvRA4O1V//CQY7Pc5lfrMCuDuvwB+AWBmTwOfdvdtCU2qgCUJ8+XE+zqqCP/36l/YnShhPoAZJHRgAS8ClwbTBizoZ70VxPciejqlLgiWXwt8M5g+kvgup2V45kkJbW4Afpfp73OvNttIQad3it7rOQltPg/8IQsynwesB0pS8R6n8vPBIHd6H2pW+u/03kr8iERxMD0u2c99WI/QA4T2i8NdQDXQSbyqX0X8L9dHgdXBP5Kv97NuBbAW2AzcyoELIIcB/xM89xpwVhZk/m/gDWAN8b/cJmV65l5ttpGas6RS8V7fHSxfQ3z8nilZkPlt4n/4vB48BvvMrlRkXha8VjtQAzwWZlb6KBjB8iuD9/dt4DMf5HMf1kNXeouISFJ0lpSIiCRFBUNERJKigiEiIklRwRARkaSoYIiISFJUMCSnmVlLmrd3h5kdPUiv1W3xkW3XmtkDBxsp1szGmtnfD8a2Rfqi02olp5lZi7uPHsTXy/MDg/GlVGJ2M/sV8Ja7f2eA9jOAB939mHTkk6FHexgy5JhZiZndbWYrgsdpwfLFZvaima0Kfs4Nln/azH5vZg8Aj5vZEjN72sz+YPF7Rfym554FwfKKYLolGGxwtZm9bGZlwfLZwfwKM/tmkntBL3Fg8MXRZvaEmb1m8fsmXBS0uQmYHeyV3By0/VKwnTVm9q+D+DbKEKSCIUPRT4AfufuJwMeBO4LlG4Ez3H0h8ZFkv5uwzinAFe5+VjC/EPgicDQwCzitj+2MAl529wXAs8DfJmz/J8H2DzpOUDCO0tnEr8QHaAOWufsJxO/B8sOgYH0F2Ozux7v7l8zsHGAOsBg4HlhkZmccbHsi/dHggzIUfRg4OmGE0TFmVggUAb8ysznERwjNT1hnubsn3gvhVXevAjCz14mPMfR8r+10cGAwx5XAR4LpUzhwj4PfAj/oJ+eIhNdeSfyeCRAfY+i7wZd/jPieR1kf658TPFYF86OJF5Bn+9meyIBUMGQoigCnuPv+xIVm9h/AU+6+LOgPeDrh6dZer9GeMN1N3/+WOv1AJ2F/bQay392PN7Mi4oXnOuAW4vfSKAEWuXunmW0DCvpY34DvufvPPuB2RfqkQ1IyFD1O/F4UAJhZz/DURcCOYPrTKdz+y8QPhQFcdrDG7t5I/JauN5pZPvGctUGxWApMD5o2A4UJqz4GXBnctwEzm2JmpYP0O8gQpIIhuW6kmVUlPP6B+JdvRdARvJ74sPQA/wZ8z8xeAKIpzPRF4B/M7FVgEtB4sBXcfRXxEVEvI34TowozqyS+t7ExaLMbeCE4Dfdmd3+c+CGvl8zsDeAPvL+giHwgOq1WJM2Cuwbud3c3s8uAy939ooOtJxI29WGIpN8i4NbgzKa9pPCWuCKDSXsYIiKSFPVhiIhIUlQwREQkKSoYIiKSFBUMERFJigqGiIgkRQVDRESS8v8BI5/w1Z1MevcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Fit one cycle using an appropriate learning rate and save the model if you like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "TD26zizeqtw0",
    "outputId": "079fbff5-5722-4b15-a8eb-a1b137af4e0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 1:00:35 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.890449</td>\n",
       "      <td>3.762490</td>\n",
       "      <td>0.357238</td>\n",
       "      <td>1:00:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nZXPvFvYq6fq"
   },
   "outputs": [],
   "source": [
    "learn.save('wikita_8k_447_first', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8IvrTR9Bq-_5"
   },
   "outputs": [],
   "source": [
    "learn.load('wikita_8k_447_first', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.05162599159145"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.7624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10. Now fit a few more cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cjr8tciMrA7g"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "hpRsAQbkrItO",
    "outputId": "e73ebf03-a7a3-4dcb-c3d8-fc66ff7bb8cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 5:01:00 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.682452</td>\n",
       "      <td>3.898896</td>\n",
       "      <td>0.341597</td>\n",
       "      <td>1:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.829053</td>\n",
       "      <td>3.884494</td>\n",
       "      <td>0.342567</td>\n",
       "      <td>1:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.478386</td>\n",
       "      <td>3.672344</td>\n",
       "      <td>0.366506</td>\n",
       "      <td>1:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.480849</td>\n",
       "      <td>3.440922</td>\n",
       "      <td>0.394125</td>\n",
       "      <td>1:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.475762</td>\n",
       "      <td>3.332312</td>\n",
       "      <td>0.406661</td>\n",
       "      <td>1:00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EQ7GEC2W3BDW"
   },
   "outputs": [],
   "source": [
    "learn.save('wikita_8k_447_second', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UGegtbfq3Dzs"
   },
   "outputs": [],
   "source": [
    "learn.load('wikita_8k_447_second', with_opt=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11. Finally, with smaller learning rate fine tune the model for lot more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1498
    },
    "colab_type": "code",
    "id": "Jq0tUpNO5AcT",
    "outputId": "62d4657b-6238-4715-ee47-480425c1850d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [8/10 7:25:01<1:51:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.273025</td>\n",
       "      <td>3.223268</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.241727</td>\n",
       "      <td>3.258525</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.188190</td>\n",
       "      <td>3.144011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.239507</td>\n",
       "      <td>3.027930</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.316402</td>\n",
       "      <td>3.049245</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.221811</td>\n",
       "      <td>3.049403</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.225265</td>\n",
       "      <td>3.028381</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>55:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.759860</td>\n",
       "      <td>2.986449</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='7714', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-161bd06a200b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aVkQtpFY5W1s"
   },
   "outputs": [],
   "source": [
    "learn.save('wikitalm_8k_447_third', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "90ugxdMT5X9q"
   },
   "outputs": [],
   "source": [
    "learn.load('wikitalm_8k_447_third', with_opt=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12. Calculate perplexity of the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FrbfD8SDrapi",
    "outputId": "cc83bf92-8b36-487b-fdb4-c0aeedfac19b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.806298635156402"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.986)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yslflc_jekDw"
   },
   "source": [
    "## Step 13. Probe the LM by asking it to complete phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Uwi_eROg3rFG"
   },
   "outputs": [],
   "source": [
    "def create(text, spm=False, N_WORDS=50, N_SENTENCES=4):\n",
    "    TEXT=sp.EncodeAsPieces(text)\n",
    "    TEXT=' '.join(TEXT)\n",
    "    sp_merge=lambda s:s.replace(' ','').replace('▁',' ')\n",
    "    samples=[]\n",
    "    for _ in range(N_SENTENCES):\n",
    "      sample=learn.predict(TEXT, N_WORDS, temperature=0.7)\n",
    "      samples.append(sample)\n",
    "      if spm:\n",
    "          print(sample)\n",
    "          print()\n",
    "    if spm:\n",
    "        print()\n",
    "    for sample in samples:\n",
    "      sample=sp_merge(sample)\n",
    "      print(sample)\n",
    "      print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "o2TerKS1rgh6",
    "outputId": "b790084f-bf5b-4615-ab5b-0dcf3d72a737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁முதல் ▁உலகப் போர் ▁முடிவடைந்த து . ▁தனது ▁ஆட்சி க் ▁காலத்தில் ▁பிரான்சின் ▁அரசு த்தலைவர் ▁ மன் ஹா ட்டன் ▁ஒரு வரை த் ▁தேர்ந்தெடுத்த ு , ▁சோ தி க்க ▁வேண்டிய ▁பொறுப்பு ம் ▁ஆ க்கப்பட்டு , ▁நாட்டின் ▁பொருளாதார த்தைக் ▁கொண்டுவர வும் , ▁தமது ▁கட்டிட ங்களை ▁மாற்றி க்கொள்ள வும் ▁முயற்சி ▁செய்தார் . ▁அதனால் , ▁அவர்\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁ டெல் டா ▁எனும் ▁இடத்தில் ▁ஒரு ▁குடியிருப்பு ப் ▁பகுதியில் ▁உள்ளது . ▁இந்த ▁ஊர் ▁7 000 ▁சதுர ▁அடி ▁பரப்ப ள விற்கு ▁மேல் ▁அமைந்துள்ளது . ▁இங்கு ▁5 000 ▁அடி ▁உயர முள்ள ▁இந்த ▁கோவில ும் , ▁கி றி ஸ் து வ ▁மத த்தின் ▁ஒரு ▁பகுதியாக வும் ▁உள்ளது . ▁< ▁ / ▁ doc\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் , ▁ பிரான் சில் ▁உள்ள ▁ ஃபோர்ட் ▁பிரா ங்க் ளின் , ▁டெ ன் ▁மற்றும் ▁\" இ . அ . கா ம் \" ▁என்ற ▁இரு தி ட க் ▁கூறு களை ▁கொண்டு , ▁இ க்கட்ட ளை ▁ கியூ ரி யின் ▁அ கு ஸ் தா க் ▁யோ ச னை யில் ▁அமைந்துள்ள ▁ஒரு ▁ஸ்\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁ வல் கன் ▁ ரன் ▁எனக் ▁கருதப்பட்ட னர் . ▁அ ம் ரி த் சர் , ▁லி ஹி லியா , ▁வெ னி சு லா , ▁லி சி யே சி யே ▁ஆகும் . ▁இது ▁எ த்தி யோ ப் பியா , ▁லி மா பார் ▁போன்ற ▁நாடுகளில் ▁இருந்த ▁ஒரு ▁பகுதி ▁ஆகும் . ▁இது ▁உலகில்\n",
      "\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் முதல் உலகப்போர் முடிவடைந்தது. தனது ஆட்சிக் காலத்தில் பிரான்சின் அரசுத்தலைவர் மன்ஹாட்டன் ஒருவரைத் தேர்ந்தெடுத்து, சோதிக்க வேண்டிய பொறுப்பும் ஆக்கப்பட்டு, நாட்டின் பொருளாதாரத்தைக் கொண்டுவரவும், தமது கட்டிடங்களை மாற்றிக்கொள்ளவும் முயற்சி செய்தார். அதனால், அவர்\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் டெல்டா எனும் இடத்தில் ஒரு குடியிருப்புப் பகுதியில் உள்ளது. இந்த ஊர் 7000 சதுர அடி பரப்பளவிற்கு மேல் அமைந்துள்ளது. இங்கு 5000 அடி உயரமுள்ள இந்த கோவிலும், கிறிஸ்துவ மதத்தின் ஒரு பகுதியாகவும் உள்ளது. < / doc\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில், பிரான்சில் உள்ள ஃபோர்ட் பிராங்க்ளின், டென் மற்றும் \"இ.அ.காம்\" என்ற இருதிடக் கூறுகளை கொண்டு, இக்கட்டளை கியூரியின் அகுஸ்தாக் யோசனையில் அமைந்துள்ள ஒரு ஸ்\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் வல்கன் ரன் எனக் கருதப்பட்டனர். அம்ரித்சர், லிஹிலியா, வெனிசுலா, லிசியேசியே ஆகும். இது எத்தியோப்பியா, லிமாபார் போன்ற நாடுகளில் இருந்த ஒரு பகுதி ஆகும். இது உலகில்\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text='17-ஆம் நூற்றாண்டில்'\n",
    "create(text, spm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "SNMpnfoWekD8",
    "outputId": "c005441a-c096-4e00-cb21-e6669a1a8641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " இந்த கிராமத்தில் வாழும் வாழ்க்கையைப் பின்பற்றியவர்கள். இதற்கு மாற்றாக, பொது மக்கள் அனைவரும் இதைப் பயன்படுத்த வேண்டும் என்ற கொள்கையை உடையவர்களாக இருந்தனர். இந்த விளைவைத் தோழமை செய்யும் வகையில், ஒரு தொழில் நுட்பம், மற்றும் பரந்த கிராமப்புறங்கள், பாறைகள் போன்றவற்றைக் கொண்டு அமைக்கப்பட்டிருக்கும்\n",
      "\n",
      " இந்த கிராமத்தில், ஆங்கராவின் வழிவந்தோர் புலிகள் ஆகும். இது ஒரு ஆன்மிகப் புகழ்ச்சி ஆகும். இதன் மூலம் மனிதனைப் பெண்களால் உருவாக்கலாம். பலவகையான உடல் முறைகளை உட்கொண்டு, உடலைப் பொருத்தி, விலங்குகளின் உடலில் இருந்து\n",
      "\n",
      " இந்த கிராமத்தில் பகுக்கப்பட்டுள்ளது, மற்றும் பல மக்களின் மேம்பாட்டிற்காகவும் அழகு படுத்தப்படுகிறது. < / doc> <doc id=\"323593\" url=\"https: / / ta.wikipedia.org / wiki?curid\n",
      "\n",
      " இந்த கிராமத்தில் உள்ள ஒரு கிராமம். அக்கோடிடே, அய்லி, அயன், நயனை, நாகாலா, சபிசி, சிரினா, விதாவகி, எமரு, வசித்தி, யேரா போன்ற ச\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create('இந்த கிராமத்தில்')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "QyYFlbHVekD_",
    "outputId": "9a8c4fea-ce55-42af-e0e4-f24a27e5e2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1995 ம் ஆண்டு முதல் 2000 வரை. எஃப்.எசு. ஹால்ஸ் மற்றும் ஜெர்ரி வாட்டர்ஸ் ஆகியோரால் கண்டுபிடிக்கப்பட்ட இப்புத்தகத்தடத்திலிருந்து எடுக்கப்பட்ட அறிமுறை முன்னூகிக்கும் ஒருவகைப் பெயர். இந்த ஒரே மாதிரியான அனைத்து ஆர்.எஸ்.\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை கொந்தளிப்புகள், குத்துயரங்கள், பாக்குகள், ட்ரெத்கள் மற்றும் ரைன்டர்கள் என பலவகையான மொழிகளைப் பயன்படுத்தினர். இவர்கள் லத்தீன் பேசியவர்கள். ஆனாலும், நவீன பிரெஞ்சுக்காரர்கள்\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை மாட்டுநடுவிலும், லைப்னிட்ஸ், பூர்ட் (மருந்து) , பிரதிஷ்டை , புர்காம் , ஹவாய் வடக்கு , கச டுவாட் நில்சௌ டுரூ\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை இது நிகழ்ந்துள்ளது. அந்தச் சமயத்தில் மாற்றம் அடைந்து வெளிநாடுகளில் இருந்து வெளியேறியதால் பல லட்சம் பேர் இறந்தனர். இந்த நாள் விக்டோரிய மக்கள் தொகைக் கணக்கெடுப்புகளில் 5.6 சதவீதமானோர் இங்கு வந்து குடியேறியுள்ளனர். இவர்களில் பெரும்பான்மையானோர் 85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create('1995 ம் ஆண்டு முதல் 2000 வரை')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create('இந்த விபத்தில் ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14. Prompt it to write entirely imagined new Wiki Articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SETePMlEekEB",
    "outputId": "ee1176a6-843b-4fc9-d835-473bffd515e0"
   },
   "outputs": [],
   "source": [
    "create('<doc id=\"208219\" url=\"https://ta.wikipedia.org/wiki?curid=', N_WORDS=200, N_SENTENCES=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eAkiW7ITekET"
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next steps\n",
    "- Try the same notebook for another language\n",
    "- Try Transformer, Transformer XL, GPT-2\n",
    "- Explore the LM\n",
    "- Test out the LM on classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FastLM_Tamil.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
