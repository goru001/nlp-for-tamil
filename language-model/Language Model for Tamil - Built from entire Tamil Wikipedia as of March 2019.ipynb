{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0AWt_a15m68f"
   },
   "source": [
    "\n",
    "# Language Model for Tamil - Built from entire Tamil Wikipedia\n",
    "\n",
    "First Draft: Ravi Annaswamy April 6, 2019.\n",
    "\n",
    "\n",
    "## What is a Language Model?\n",
    "\n",
    "What is a Model, first of all? A model is a organized knowledge-store that can help predict what will happen in various situations. \n",
    "\n",
    "Model of the solar system helps  us predict when will Sun rise at a given place on globe on a given day.\n",
    "\n",
    "A language model, similarly helps predict what word will come next in a sequence of words. This is done by the model systematically learning what usually comes in a context. \n",
    "\n",
    "\n",
    "## Why is it needed?\n",
    "\n",
    "Humans interpret what is being said, because they have the mental model of the language. That is how we know that 'dog bites a man' is different from 'man bites a dog'.\n",
    "\n",
    "Understanding speech in a noisy room, finding and fixing spelling mistakes, and grammatical mistakes are immediate obvious uses of a language model. But it goes more than that. ALL OUR COMMUNICATION is noisy and partial statement, and it is made possible because listener fills in the gaps (reads between lines) because of the language and world model he shares with the speaker or writer.\n",
    "\n",
    "## How do we build a language model?\n",
    "\n",
    "Pre-2010 ngram models were the state of the art. An ngram (say a three word phrase) serving as a context and a table showing what all words followed it how many times in a large text, serves as a prediction model.\n",
    "\n",
    "With Deep learning, several breakthroughs happened in this field. \n",
    "\n",
    "First, words are mapped to meaning vectors in a continuous space so generalization becomes vastly easy. \n",
    "\n",
    "Secondly the system can figure out contexts that are optimal and useful.\n",
    "\n",
    "Third, GPU computing, wikipedia, deep learning libraries such as tensorflow, keras, pytorch and fastai have made doing this a piece of cake.\n",
    "\n",
    "As you will see, we can build a state of the art language model for any language in less than four hours, from collecting text, to tokenizer construction to language model. This is a miracle.\n",
    "\n",
    "Also, even though these are termed as language models, they go beyond just figuring out the grammar (syntax), they also recognize patterns in usage, semantics, so they are a model of the world to the extent it can be inferred from the language. This is why recent recognition that language models with very little fine tuning can be used for question answering and other natural language tasks that are not linguistic but real-world tasks.\n",
    "\n",
    "\n",
    "This code is adapted from https://github.com/goru001/nlp-for-hindi/blob/master/language-model/Hindi_Language_Model.ipynb\n",
    "\n",
    "Modifications for tamil:\n",
    "\n",
    "- Chose to use 8000 word vocabulary for Sentence Piece.\n",
    "\n",
    "- Perplexity of ~20 when trained on 120,000 articles.\n",
    "\n",
    "- Updated the text generator section with a slightly better probing function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. Get the Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZ9dGP92ej_l"
   },
   "source": [
    "## Step 1. Install fastai Deep Learning Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "yH7WdaZ8ekBo",
    "outputId": "69dec13f-0fde-4175-99a1-abeb9b31c594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Using cached https://files.pythonhosted.org/packages/44/cc/dcc702cf43bb8c908d172e5be156615928f962366a20834c320cbca2b9d0/fastai-1.0.51-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-ml-py3 in /home/ravi_annaswamy/.local/lib/python3.7/site-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (18.0)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: spacy>=2.0.18 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.0.18)\n",
      "Requirement already satisfied, skipping upgrade: numexpr in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.6.8)\n",
      "Requirement already satisfied, skipping upgrade: bottleneck in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: typing in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (3.6.4)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: Pillow in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (5.3.0)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: fastprogress>=0.1.19 in /home/ravi_annaswamy/.local/lib/python3.7/site-packages (from fastai) (0.1.20)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /opt/anaconda3/lib/python3.7/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib->fastai) (2.7.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/anaconda3/lib/python3.7/site-packages (from packaging->fastai) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (6.12.1)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (1.35)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (0.2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /opt/anaconda3/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2018.1.10)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /opt/anaconda3/lib/python3.7/site-packages (from pandas->fastai) (2018.7)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (2018.11.29)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.6.3)\n",
      "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.5.6)\n",
      "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.4.3.2)\n",
      "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0.1)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (1.10.11)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy>=2.0.18->fastai) (0.9.0)\n",
      "Installing collected packages: fastai\n",
      "  Found existing installation: fastai 1.0.50.post1\n",
      "    Uninstalling fastai-1.0.50.post1:\n",
      "      Successfully uninstalled fastai-1.0.50.post1\n",
      "  Rolling back uninstall of fastai\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/opt/anaconda3/lib/python3.7/site-packages/fastai/__init__.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8jnu89DnBtB"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2PX5-Ysmg_Y"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Grnm1xnJnDz4",
    "outputId": "5bc8a832-d82a-4958-e20a-ed2f0b17e2a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.50.post1', '1.0.1.post2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Turn on GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjVLJcJFnGk5"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Get list of text files for training, and create validation subset of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lN60HogbnJvI"
   },
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-tamil/language-model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the following to tawiki_small if you want to train on all 12000 articles. The small one here is a subset of 40000 articles for quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "iR9sJEytnNYX",
    "outputId": "26457d8a-d555-44a1-c5cb-29f2847d51bd"
   },
   "outputs": [],
   "source": [
    "p = path.glob('../corpus/tawiki/tawiki_large/*/*.txt')\n",
    "files = [str(x) for x in p if x.is_file()]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please note: if you want to quick experiment on this data to get a feel for the code, please choose a smaller subset of files.\n",
    " you can modify the following line to choose only 20 of the 447 files.\n",
    " \n",
    " train_files, test_files = train_test_split(files*[:20]*, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VJZRIcK6nbnL"
   },
   "outputs": [],
   "source": [
    "train_files, test_files = train_test_split(files, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hcDJVUhJny9W",
    "outputId": "e13602d5-ded6-474d-ddf7-4fe2dfddec92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 90)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Lgi8MjMjioRC"
   },
   "outputs": [],
   "source": [
    "def get_article_count(filelist):\n",
    "  AC=0\n",
    "  for f in filelist:\n",
    "    with open(f, encoding='utf-8') as fp:\n",
    "      text=fp.read()\n",
    "      AC+=text.count('<doc id')\n",
    "  return AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IJB5XHB-i6BM",
    "outputId": "87652596-11f9-487f-d56a-6f37d0370811"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102126, 25255)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_count(train_files), get_article_count(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Copy files from tamil wiki into train and valid folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ik0ciqcBoGKy",
    "outputId": "bdf913e5-46e3-44dc-d116-2832700c9509"
   },
   "outputs": [],
   "source": [
    "!mkdir TamilWikiDataset\n",
    "!mkdir TamilWikiDataset/train\n",
    "!mkdir TamilWikiDataset/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dkDkZNiOn2YN"
   },
   "outputs": [],
   "source": [
    "# Preparing dataset for fastai\n",
    "for file in train_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(path/'TamilWikiDataset'/'train'/(str(file).split('/')[-1]), \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6dfzJHzNoSff"
   },
   "outputs": [],
   "source": [
    "for file in test_files:\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    with open(path/'TamilWikiDataset'/'valid'/(str(file).split('/')[-1]), \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6201
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hxw6AUsRDoQ8",
    "outputId": "b9250c04-76ef-45b0-9ec7-986d828c2535"
   },
   "outputs": [],
   "source": [
    "#!zip -r train.zip TamilWikiDataset/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1589
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7eLWYQ6BDosd",
    "outputId": "8e4eb8f7-491b-45ab-8473-64aabbb68142"
   },
   "outputs": [],
   "source": [
    "#!zip -r valid.zip TamilWikiDataset/valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III. Setup learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Define Tamil Tokenizer by wrapping our SP model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are creating a tokenizer that will use the rules from the sentencepiece model, to split each sentence into its root parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BhdVU9NSmJHp"
   },
   "outputs": [],
   "source": [
    "#class TamilTokenizer(BaseTokenizer):\n",
    "#    def __init__(self, lang:str):\n",
    "#        self.lang = lang\n",
    "#        self.sp = spm.SentencePieceProcessor()\n",
    "#        self.sp.Load(str(\"tamil_spm_8k.model\"))\n",
    "#        \n",
    "#    def tokenizer(self, t:str) -> List[str]:\n",
    "#        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am placing this inside inltk package, to allow inltk to use this tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import TamilTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5PFgPbLolhr"
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str('tamil_spm_8k.model'))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gtnD-okorAR"
   },
   "outputs": [],
   "source": [
    "tamil_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46wIzsm_pCgk"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=TamilTokenizer, lang='ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "8VFukVAipIfj",
    "outputId": "64882e15-85ae-44bc-dda2-97e768f00116"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-tamil/language-model')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Create Fast AI Data generator from the train and valid paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27mkuLLHpOGy"
   },
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'TamilWikiDataset', tokenizer=tokenizer, vocab=tamil_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kIALPhGSpR6i",
    "outputId": "b77406cf-12f2-4c37-e747-135718bd7f81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LJJUt5e7pVHY"
   },
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_tawiki_8k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "sRXTWQA7pXjg",
    "outputId": "59043ec4-fba5-4eb2-905e-4286dc890d23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>நோ யாகும் . ▁இது ▁முதற் கல வு ரு ▁ஒட்டு ண்ணி கள் ▁மூலம் ▁ஏற்படுகிறது . ▁அமெரிக்கா , ▁ஆசியா ▁மற்றும் ▁ஆப்பிரிக்கா ▁ஆகிய ▁பகுதி களையும் ▁சேர்த்து ▁வெப்ப ▁வலய ம் ▁சார்ந்த ▁மற்றும் ▁மித வெப்ப ▁மண்டல ▁பிரதேச ங்களிலும் ▁இது ▁பரவலாக க் ▁காணப்படுகிறது . ▁ஒவ்வொரு ▁ஆண்டு ம் ▁தோராயமாக ▁3 50 ▁முதல் ▁500 ▁மில்லியன் ▁வரையிலான ▁மக்கள் ▁ம லே ரியா ▁நோ யினால் ▁பாதிக்கப்பட ுகிறார்கள் . ▁அவற்றில் ▁ஒன்ற ிலிருந்து ▁மூன்று ▁மில்லியன் ▁மக்கள் ▁இந்த ▁நோ யினால் ▁இறக்க ிறார்கள் .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>. ▁இத்த ெ ரு வில் ▁நடக்கும் ▁அன்றாட ▁நிகழ்வு களை ▁அடிப்படையாக ▁வைத்து , ▁வெளிவந்த ▁திரைப்பட மே , ▁அ ங்கா டி த் ▁தெரு ▁ஆகும் . ▁&lt; ▁ / ▁ doc &gt; ▁&lt; doc ▁id =\" 14 93 09 \" ▁ url =\" https : ▁ / ▁ / ▁ ta . wikipedia . org ▁ / ▁ wiki ? curi d = 14 93 09 \" ▁title =\" ரோ சா ப்பூ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>டன் ▁வெற்றிகரமான ▁அறுவடை ▁மேற்கொள்ள ப்படுகிறது . ▁அவரை க் ▁குடும்ப த் ▁தாவர ங்களைச் ▁' சு ழற்சி முறை ' ப் ▁பயிர் களாகப் ▁பயன்படுத்திய மை யே ▁இவ் ▁வெற்றி க்குக் ▁காரணமாக ும் . ▁மேலும் , ▁சென்ற ▁பதி ற்ற ாண்ட ில் , ▁க னோ லா ▁வகை த் ▁தாவர த்தை ▁சுழற்சி முறை ப் ▁ப யிர ாகப் ▁பயன்படுத்திய தின் ▁விளைவாக ▁கோதுமை ▁விளை ச்சல் ▁25 % ▁அதிகரித்த ுள்ளது . ▁மழை வீ ழ் ச்சி ▁குறைந்த ▁இப் பிரதேச ங்களில்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ப் ▁பெற்றார் . ▁நிறைய ▁போட்டிகளில் ▁விளையாடிய ▁பிற கே ▁தனது ▁முதல் ▁தேர்வுத் ▁துடுப்பாட்ட ▁\" கே ட் சை ப் \" ▁பிடித்த ார் . ▁அக்டோபர் ▁31 , ▁2016 ▁இல் ▁மேற் கி ந்திய த்தீவு கள் ▁துடுப்பாட்ட ▁அணிக்கு ▁எதிரான ▁தனது ▁20 ▁ஆவது ▁தேர்வு ப் ▁போட்டியில் ▁டே ரன் ▁பிரா வோ ▁அடி த்த ▁ப ந்தை ▁அற்புத மாக ப் ▁பிடித்து ▁அவரை ▁வீழ்த்த ▁உதவி னார் . ▁2010 ▁ஆம் ▁ஆண்டில் ▁ஆத்திரேலிய த் ▁துடுப்பாட்ட ▁அணிக்கு ▁எதிரான ▁பன்னாட்டு ▁இருபது 20 ▁போட்டியில்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>மான &lt;unk&gt; &lt;unk&gt; h e &lt;unk&gt; &lt;unk&gt; r u t h &lt;unk&gt; ▁b o o k ▁ யெ கோ வா வின் ▁ச ாட்சி ▁ கள் ▁\" , ம த்தி யில் ▁து ஷ் பிர யோ கம் ▁செய்யப்பட்டு ▁தப்பி த்து ▁வந்த ▁ஒரு ▁குழந்தை யின் ▁உண்மை க்கதை யாக ▁2005 ▁ஆம் ▁ஆண்டு ▁வெளியிடப்பட்டது . ▁இது ▁தவிர ▁கவிதைகள் ▁மற்றும் ▁சிறு ▁கதை களையும் &lt;unk&gt; &lt;unk&gt; ell ▁ or &lt;unk&gt; &lt;unk&gt; ig h &lt;unk&gt; ▁w at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vVI3riA8paS3",
    "outputId": "99ca1874-a5a2-4f00-e7e8-89f4531939ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eP2YMhDekDF"
   },
   "source": [
    "## Step 8. Create a LM Learner object and run it once to estimate good learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFcI91lTvgBV"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TamilWikiDataset/data_lm_tawiki_8k.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d02e04052631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TamilWikiDataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_lm_tawiki_8k.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai-bleed/lib/python3.6/site-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, fname, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                   no_check:bool=False, **kwargs)->DataBunch:\n\u001b[1;32m    275\u001b[0m     \u001b[0;34m\"Load from `path/fname` a saved `DataBunch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,\n\u001b[1;32m    278\u001b[0m                         collate_fn=collate_fn, no_check=no_check, **kwargs)\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-bleed/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TamilWikiDataset/data_lm_tawiki_8k.pkl'"
     ]
    }
   ],
   "source": [
    "data_lm = load_data('TamilWikiDataset', 'data_lm_tawiki_8k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1r5RCuypjsG"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0yybfjejprBU",
    "outputId": "b2a72e5f-23b7-420d-df9f-2f2315c00ae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV. Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qXYCz5voqodX",
    "outputId": "32a2a937-799f-4813-d970-fa6c77716b48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "OjGZ5zP4qrat",
    "outputId": "9fdd2b83-535e-48fc-86c3-33e841eeb56b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Fit one cycle using an appropriate learning rate and save the model if you like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "TD26zizeqtw0",
    "outputId": "079fbff5-5722-4b15-a8eb-a1b137af4e0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 1:00:35 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.890449</td>\n",
       "      <td>3.762490</td>\n",
       "      <td>0.357238</td>\n",
       "      <td>1:00:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nZXPvFvYq6fq"
   },
   "outputs": [],
   "source": [
    "learn.save('wikita_8k_447_first', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8IvrTR9Bq-_5"
   },
   "outputs": [],
   "source": [
    "learn.load('wikita_8k_447_first', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.05162599159145"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.7624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10. Now fit a few more cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cjr8tciMrA7g"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "hpRsAQbkrItO",
    "outputId": "e73ebf03-a7a3-4dcb-c3d8-fc66ff7bb8cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 5:01:00 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.682452</td>\n",
       "      <td>3.898896</td>\n",
       "      <td>0.341597</td>\n",
       "      <td>1:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.829053</td>\n",
       "      <td>3.884494</td>\n",
       "      <td>0.342567</td>\n",
       "      <td>1:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.478386</td>\n",
       "      <td>3.672344</td>\n",
       "      <td>0.366506</td>\n",
       "      <td>1:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.480849</td>\n",
       "      <td>3.440922</td>\n",
       "      <td>0.394125</td>\n",
       "      <td>1:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.475762</td>\n",
       "      <td>3.332312</td>\n",
       "      <td>0.406661</td>\n",
       "      <td>1:00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EQ7GEC2W3BDW"
   },
   "outputs": [],
   "source": [
    "learn.save('wikita_8k_447_second', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UGegtbfq3Dzs"
   },
   "outputs": [],
   "source": [
    "learn.load('wikita_8k_447_second', with_opt=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11. Finally, with smaller learning rate fine tune the model for lot more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1498
    },
    "colab_type": "code",
    "id": "Jq0tUpNO5AcT",
    "outputId": "62d4657b-6238-4715-ee47-480425c1850d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [8/10 7:25:01<1:51:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.273025</td>\n",
       "      <td>3.223268</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.241727</td>\n",
       "      <td>3.258525</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.188190</td>\n",
       "      <td>3.144011</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.239507</td>\n",
       "      <td>3.027930</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.316402</td>\n",
       "      <td>3.049245</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.221811</td>\n",
       "      <td>3.049403</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.225265</td>\n",
       "      <td>3.028381</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>55:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.759860</td>\n",
       "      <td>2.986449</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>55:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='7714', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-161bd06a200b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aVkQtpFY5W1s"
   },
   "outputs": [],
   "source": [
    "learn.save('wikitalm_8k_447_third', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90ugxdMT5X9q"
   },
   "outputs": [],
   "source": [
    "learn.load('wikitalm_8k_447_third', with_opt=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12. Calculate perplexity of the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FrbfD8SDrapi",
    "outputId": "cc83bf92-8b36-487b-fdb4-c0aeedfac19b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.806298635156402"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.986)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yslflc_jekDw"
   },
   "source": [
    "## Step 13. Probe the LM by asking it to complete phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Uwi_eROg3rFG"
   },
   "outputs": [],
   "source": [
    "def create(text, spm=False, N_WORDS=50, N_SENTENCES=4):\n",
    "    TEXT=sp.EncodeAsPieces(text)\n",
    "    TEXT=' '.join(TEXT)\n",
    "    sp_merge=lambda s:s.replace(' ','').replace('▁',' ')\n",
    "    samples=[]\n",
    "    for _ in range(N_SENTENCES):\n",
    "      sample=learn.predict(TEXT, N_WORDS, temperature=0.7)\n",
    "      samples.append(sample)\n",
    "      if spm:\n",
    "          print(sample)\n",
    "          print()\n",
    "    if spm:\n",
    "        print()\n",
    "    for sample in samples:\n",
    "      sample=sp_merge(sample)\n",
    "      print(sample)\n",
    "      print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "o2TerKS1rgh6",
    "outputId": "b790084f-bf5b-4615-ab5b-0dcf3d72a737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁முதல் ▁உலகப் போர் ▁முடிவடைந்த து . ▁தனது ▁ஆட்சி க் ▁காலத்தில் ▁பிரான்சின் ▁அரசு த்தலைவர் ▁ மன் ஹா ட்டன் ▁ஒரு வரை த் ▁தேர்ந்தெடுத்த ு , ▁சோ தி க்க ▁வேண்டிய ▁பொறுப்பு ம் ▁ஆ க்கப்பட்டு , ▁நாட்டின் ▁பொருளாதார த்தைக் ▁கொண்டுவர வும் , ▁தமது ▁கட்டிட ங்களை ▁மாற்றி க்கொள்ள வும் ▁முயற்சி ▁செய்தார் . ▁அதனால் , ▁அவர்\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁ டெல் டா ▁எனும் ▁இடத்தில் ▁ஒரு ▁குடியிருப்பு ப் ▁பகுதியில் ▁உள்ளது . ▁இந்த ▁ஊர் ▁7 000 ▁சதுர ▁அடி ▁பரப்ப ள விற்கு ▁மேல் ▁அமைந்துள்ளது . ▁இங்கு ▁5 000 ▁அடி ▁உயர முள்ள ▁இந்த ▁கோவில ும் , ▁கி றி ஸ் து வ ▁மத த்தின் ▁ஒரு ▁பகுதியாக வும் ▁உள்ளது . ▁< ▁ / ▁ doc\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் , ▁ பிரான் சில் ▁உள்ள ▁ ஃபோர்ட் ▁பிரா ங்க் ளின் , ▁டெ ன் ▁மற்றும் ▁\" இ . அ . கா ம் \" ▁என்ற ▁இரு தி ட க் ▁கூறு களை ▁கொண்டு , ▁இ க்கட்ட ளை ▁ கியூ ரி யின் ▁அ கு ஸ் தா க் ▁யோ ச னை யில் ▁அமைந்துள்ள ▁ஒரு ▁ஸ்\n",
      "\n",
      "▁17 - ஆம் ▁நூற்றாண்டில் ▁ வல் கன் ▁ ரன் ▁எனக் ▁கருதப்பட்ட னர் . ▁அ ம் ரி த் சர் , ▁லி ஹி லியா , ▁வெ னி சு லா , ▁லி சி யே சி யே ▁ஆகும் . ▁இது ▁எ த்தி யோ ப் பியா , ▁லி மா பார் ▁போன்ற ▁நாடுகளில் ▁இருந்த ▁ஒரு ▁பகுதி ▁ஆகும் . ▁இது ▁உலகில்\n",
      "\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் முதல் உலகப்போர் முடிவடைந்தது. தனது ஆட்சிக் காலத்தில் பிரான்சின் அரசுத்தலைவர் மன்ஹாட்டன் ஒருவரைத் தேர்ந்தெடுத்து, சோதிக்க வேண்டிய பொறுப்பும் ஆக்கப்பட்டு, நாட்டின் பொருளாதாரத்தைக் கொண்டுவரவும், தமது கட்டிடங்களை மாற்றிக்கொள்ளவும் முயற்சி செய்தார். அதனால், அவர்\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் டெல்டா எனும் இடத்தில் ஒரு குடியிருப்புப் பகுதியில் உள்ளது. இந்த ஊர் 7000 சதுர அடி பரப்பளவிற்கு மேல் அமைந்துள்ளது. இங்கு 5000 அடி உயரமுள்ள இந்த கோவிலும், கிறிஸ்துவ மதத்தின் ஒரு பகுதியாகவும் உள்ளது. < / doc\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில், பிரான்சில் உள்ள ஃபோர்ட் பிராங்க்ளின், டென் மற்றும் \"இ.அ.காம்\" என்ற இருதிடக் கூறுகளை கொண்டு, இக்கட்டளை கியூரியின் அகுஸ்தாக் யோசனையில் அமைந்துள்ள ஒரு ஸ்\n",
      "\n",
      " 17-ஆம் நூற்றாண்டில் வல்கன் ரன் எனக் கருதப்பட்டனர். அம்ரித்சர், லிஹிலியா, வெனிசுலா, லிசியேசியே ஆகும். இது எத்தியோப்பியா, லிமாபார் போன்ற நாடுகளில் இருந்த ஒரு பகுதி ஆகும். இது உலகில்\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text='17-ஆம் நூற்றாண்டில்'\n",
    "create(text, spm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "SNMpnfoWekD8",
    "outputId": "c005441a-c096-4e00-cb21-e6669a1a8641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " இந்த கிராமத்தில் வாழும் வாழ்க்கையைப் பின்பற்றியவர்கள். இதற்கு மாற்றாக, பொது மக்கள் அனைவரும் இதைப் பயன்படுத்த வேண்டும் என்ற கொள்கையை உடையவர்களாக இருந்தனர். இந்த விளைவைத் தோழமை செய்யும் வகையில், ஒரு தொழில் நுட்பம், மற்றும் பரந்த கிராமப்புறங்கள், பாறைகள் போன்றவற்றைக் கொண்டு அமைக்கப்பட்டிருக்கும்\n",
      "\n",
      " இந்த கிராமத்தில், ஆங்கராவின் வழிவந்தோர் புலிகள் ஆகும். இது ஒரு ஆன்மிகப் புகழ்ச்சி ஆகும். இதன் மூலம் மனிதனைப் பெண்களால் உருவாக்கலாம். பலவகையான உடல் முறைகளை உட்கொண்டு, உடலைப் பொருத்தி, விலங்குகளின் உடலில் இருந்து\n",
      "\n",
      " இந்த கிராமத்தில் பகுக்கப்பட்டுள்ளது, மற்றும் பல மக்களின் மேம்பாட்டிற்காகவும் அழகு படுத்தப்படுகிறது. < / doc> <doc id=\"323593\" url=\"https: / / ta.wikipedia.org / wiki?curid\n",
      "\n",
      " இந்த கிராமத்தில் உள்ள ஒரு கிராமம். அக்கோடிடே, அய்லி, அயன், நயனை, நாகாலா, சபிசி, சிரினா, விதாவகி, எமரு, வசித்தி, யேரா போன்ற ச\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create('இந்த கிராமத்தில்')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "QyYFlbHVekD_",
    "outputId": "9a8c4fea-ce55-42af-e0e4-f24a27e5e2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1995 ம் ஆண்டு முதல் 2000 வரை. எஃப்.எசு. ஹால்ஸ் மற்றும் ஜெர்ரி வாட்டர்ஸ் ஆகியோரால் கண்டுபிடிக்கப்பட்ட இப்புத்தகத்தடத்திலிருந்து எடுக்கப்பட்ட அறிமுறை முன்னூகிக்கும் ஒருவகைப் பெயர். இந்த ஒரே மாதிரியான அனைத்து ஆர்.எஸ்.\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை கொந்தளிப்புகள், குத்துயரங்கள், பாக்குகள், ட்ரெத்கள் மற்றும் ரைன்டர்கள் என பலவகையான மொழிகளைப் பயன்படுத்தினர். இவர்கள் லத்தீன் பேசியவர்கள். ஆனாலும், நவீன பிரெஞ்சுக்காரர்கள்\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை மாட்டுநடுவிலும், லைப்னிட்ஸ், பூர்ட் (மருந்து) , பிரதிஷ்டை , புர்காம் , ஹவாய் வடக்கு , கச டுவாட் நில்சௌ டுரூ\n",
      "\n",
      " 1995 ம் ஆண்டு முதல் 2000 வரை இது நிகழ்ந்துள்ளது. அந்தச் சமயத்தில் மாற்றம் அடைந்து வெளிநாடுகளில் இருந்து வெளியேறியதால் பல லட்சம் பேர் இறந்தனர். இந்த நாள் விக்டோரிய மக்கள் தொகைக் கணக்கெடுப்புகளில் 5.6 சதவீதமானோர் இங்கு வந்து குடியேறியுள்ளனர். இவர்களில் பெரும்பான்மையானோர் 85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create('1995 ம் ஆண்டு முதல் 2000 வரை')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create('இந்த விபத்தில் ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14. Prompt it to write entirely imagined new Wiki Articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SETePMlEekEB",
    "outputId": "ee1176a6-843b-4fc9-d835-473bffd515e0"
   },
   "outputs": [],
   "source": [
    "create('<doc id=\"208219\" url=\"https://ta.wikipedia.org/wiki?curid=', N_WORDS=200, N_SENTENCES=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eAkiW7ITekET"
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next steps\n",
    "- Try the same notebook for another language\n",
    "- Try Transformer, Transformer XL, GPT-2\n",
    "- Explore the LM\n",
    "- Test out the LM on classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-tamil/language-model')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path / 'TamilWikiDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 400])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.174485</td>\n",
       "      <td>-0.210578</td>\n",
       "      <td>0.370564</td>\n",
       "      <td>0.494773</td>\n",
       "      <td>-1.110023</td>\n",
       "      <td>0.890757</td>\n",
       "      <td>-0.033308</td>\n",
       "      <td>-0.735920</td>\n",
       "      <td>-1.146442</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454304</td>\n",
       "      <td>-0.374571</td>\n",
       "      <td>-0.124457</td>\n",
       "      <td>-0.055464</td>\n",
       "      <td>-0.280727</td>\n",
       "      <td>-0.431140</td>\n",
       "      <td>-0.672921</td>\n",
       "      <td>-1.271594</td>\n",
       "      <td>-0.043097</td>\n",
       "      <td>-0.599503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.213150</td>\n",
       "      <td>-0.035730</td>\n",
       "      <td>0.059510</td>\n",
       "      <td>0.149528</td>\n",
       "      <td>-0.792459</td>\n",
       "      <td>0.303528</td>\n",
       "      <td>-0.088352</td>\n",
       "      <td>-0.177186</td>\n",
       "      <td>-0.352764</td>\n",
       "      <td>-0.020687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276393</td>\n",
       "      <td>-0.229400</td>\n",
       "      <td>-0.175280</td>\n",
       "      <td>-0.035048</td>\n",
       "      <td>-0.108500</td>\n",
       "      <td>-0.268964</td>\n",
       "      <td>-0.514922</td>\n",
       "      <td>-0.399817</td>\n",
       "      <td>0.074859</td>\n",
       "      <td>0.080948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.212688</td>\n",
       "      <td>-0.034252</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>0.150189</td>\n",
       "      <td>-0.794856</td>\n",
       "      <td>0.308804</td>\n",
       "      <td>-0.089119</td>\n",
       "      <td>-0.174016</td>\n",
       "      <td>-0.351749</td>\n",
       "      <td>-0.024862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268096</td>\n",
       "      <td>-0.227708</td>\n",
       "      <td>-0.173513</td>\n",
       "      <td>-0.035063</td>\n",
       "      <td>-0.106040</td>\n",
       "      <td>-0.262310</td>\n",
       "      <td>-0.512204</td>\n",
       "      <td>-0.407283</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.083062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.349795</td>\n",
       "      <td>-0.123294</td>\n",
       "      <td>-0.079460</td>\n",
       "      <td>0.123450</td>\n",
       "      <td>-1.105836</td>\n",
       "      <td>0.536652</td>\n",
       "      <td>0.473493</td>\n",
       "      <td>-1.475997</td>\n",
       "      <td>0.491273</td>\n",
       "      <td>0.673826</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.970096</td>\n",
       "      <td>0.177332</td>\n",
       "      <td>-0.123421</td>\n",
       "      <td>0.116869</td>\n",
       "      <td>-0.554221</td>\n",
       "      <td>-0.926728</td>\n",
       "      <td>-0.591517</td>\n",
       "      <td>0.937839</td>\n",
       "      <td>-0.498299</td>\n",
       "      <td>0.184174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039110</td>\n",
       "      <td>-0.164002</td>\n",
       "      <td>0.819677</td>\n",
       "      <td>-0.087105</td>\n",
       "      <td>-0.942842</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>-0.013632</td>\n",
       "      <td>-0.892259</td>\n",
       "      <td>-0.540784</td>\n",
       "      <td>0.683643</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916319</td>\n",
       "      <td>-0.108441</td>\n",
       "      <td>-0.095604</td>\n",
       "      <td>0.084792</td>\n",
       "      <td>-0.307459</td>\n",
       "      <td>-0.819997</td>\n",
       "      <td>-0.508193</td>\n",
       "      <td>-0.398217</td>\n",
       "      <td>-0.093950</td>\n",
       "      <td>0.101915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.174485 -0.210578  0.370564  0.494773 -1.110023  0.890757 -0.033308   \n",
       "1 -0.213150 -0.035730  0.059510  0.149528 -0.792459  0.303528 -0.088352   \n",
       "2 -0.212688 -0.034252  0.060038  0.150189 -0.794856  0.308804 -0.089119   \n",
       "3 -0.349795 -0.123294 -0.079460  0.123450 -1.105836  0.536652  0.473493   \n",
       "4  0.039110 -0.164002  0.819677 -0.087105 -0.942842  0.033881 -0.013632   \n",
       "\n",
       "        7         8         9    ...       390       391       392       393  \\\n",
       "0 -0.735920 -1.146442  0.458800  ... -0.454304 -0.374571 -0.124457 -0.055464   \n",
       "1 -0.177186 -0.352764 -0.020687  ... -0.276393 -0.229400 -0.175280 -0.035048   \n",
       "2 -0.174016 -0.351749 -0.024862  ... -0.268096 -0.227708 -0.173513 -0.035063   \n",
       "3 -1.475997  0.491273  0.673826  ... -1.970096  0.177332 -0.123421  0.116869   \n",
       "4 -0.892259 -0.540784  0.683643  ... -1.916319 -0.108441 -0.095604  0.084792   \n",
       "\n",
       "        394       395       396       397       398       399  \n",
       "0 -0.280727 -0.431140 -0.672921 -1.271594 -0.043097 -0.599503  \n",
       "1 -0.108500 -0.268964 -0.514922 -0.399817  0.074859  0.080948  \n",
       "2 -0.106040 -0.262310 -0.512204 -0.407283  0.076857  0.083062  \n",
       "3 -0.554221 -0.926728 -0.591517  0.937839 -0.498299  0.184174  \n",
       "4 -0.307459 -0.819997 -0.508193 -0.398217 -0.093950  0.101915  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      .\n",
       "4      ,"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1315e-01, -3.5730e-02,  5.9510e-02,  1.4953e-01, -7.9246e-01,\n",
       "         3.0353e-01, -8.8352e-02, -1.7719e-01, -3.5276e-01, -2.0687e-02,\n",
       "         7.0271e-01, -1.4703e-01,  7.4531e-02,  6.2223e-01, -8.9148e-02,\n",
       "        -3.2697e-01,  2.4841e-01,  1.4575e-02,  2.3894e-01, -5.1608e-01,\n",
       "         2.4632e-01,  2.7786e-01, -5.1374e-01,  3.7280e-01,  1.6988e-01,\n",
       "         7.8987e-02,  8.2155e-02, -6.9644e-01,  5.5053e-01,  3.0106e-01,\n",
       "         5.7335e-01, -8.3915e-01,  2.7960e-01, -3.7256e-01, -5.5981e-01,\n",
       "        -4.3901e-01, -1.9851e-01,  4.2656e-01, -8.9112e-02,  3.2256e-01,\n",
       "        -2.2972e-01,  2.2242e-01, -8.1922e-01, -1.9095e-01, -3.8355e-01,\n",
       "        -6.4462e-01,  7.5018e-01,  4.4044e-01, -4.2676e-02, -5.5288e-01,\n",
       "         4.7536e-03, -5.3245e-01,  6.0183e-01,  3.5407e-02, -7.9027e-02,\n",
       "         1.9987e-01, -5.0119e-01, -7.1134e-02,  1.7056e-01, -8.6089e-02,\n",
       "         2.2013e-02, -4.0169e-01, -7.8194e-02, -6.0169e-01, -2.7248e-01,\n",
       "         1.1653e+00, -4.4544e-01,  5.3275e-01,  6.0394e-01,  4.8723e-01,\n",
       "         2.1088e-01,  5.8770e-01, -6.3761e-01, -2.2398e-01,  4.2680e-01,\n",
       "        -3.3520e-01,  3.3575e-01,  8.4721e-02, -1.1147e-01,  8.9387e-01,\n",
       "        -1.1297e-01,  1.7534e-01,  8.2993e-02, -3.7085e-01,  2.6249e-01,\n",
       "        -4.1437e-01, -2.6363e-01,  1.6518e-01,  1.6192e-01, -2.2887e-01,\n",
       "         1.3611e-01,  1.7233e-01,  3.7179e-01,  5.7553e-01, -2.7074e-02,\n",
       "         1.9805e-01,  6.0214e-01, -3.2362e-01,  4.8334e-01, -2.6776e-02,\n",
       "         1.9821e-01,  1.4402e-01,  6.5645e-01, -7.2466e-01, -4.4863e-01,\n",
       "        -6.6653e-01, -6.1461e-01, -3.4414e-01,  5.7782e-02, -9.5776e-01,\n",
       "        -1.1524e-01, -9.3227e-01, -1.5984e-01, -1.2516e-01,  1.5058e-01,\n",
       "         8.9258e-02,  4.3337e-01, -4.1929e-01,  4.2130e-02, -4.8855e-01,\n",
       "        -2.5461e-01,  1.2730e-01,  1.4792e-01,  2.5139e-01, -6.7344e-01,\n",
       "        -3.8606e-01, -4.0468e-02, -3.0091e-02,  2.6117e-02,  2.0901e-01,\n",
       "         2.7146e-01,  6.8258e-03,  4.2925e-01, -3.4099e-02,  7.4962e-02,\n",
       "         4.6469e-01,  3.2319e-01,  2.5791e-01, -3.6063e-02, -5.8723e-01,\n",
       "        -8.1995e-02,  2.9595e-01,  2.4426e-02,  2.2873e-02, -6.1433e-01,\n",
       "        -5.2058e-02,  1.2014e-01,  3.6179e-01, -2.5945e-01,  1.2162e-01,\n",
       "         2.2248e-01,  1.0493e-01, -1.1040e-01, -3.4555e-01, -2.0208e-03,\n",
       "         4.1491e-02, -6.1360e-01, -1.3198e-01, -2.1280e-01, -1.4705e-01,\n",
       "         1.0994e-01, -1.8195e-01, -6.7726e-01, -1.4787e-01,  1.1053e-01,\n",
       "         2.8911e-01, -2.4620e-01,  7.6314e-02, -6.0334e-01, -3.0797e-01,\n",
       "        -2.2170e-01, -5.5891e-02,  5.8083e-01,  1.0031e-01, -7.8043e-01,\n",
       "         3.5383e-02, -9.9728e-03, -8.9051e-02, -1.7881e-02, -3.0981e-01,\n",
       "        -5.2266e-02,  4.4799e-01,  1.2314e-02,  1.4723e-02,  6.0593e-01,\n",
       "         1.5271e-01,  7.0374e-01,  1.9025e-01, -4.0890e-01,  2.1076e-01,\n",
       "        -5.3639e-01, -2.6245e-01,  5.3234e-01, -3.3229e-01, -4.2335e-01,\n",
       "        -6.0163e-01,  2.0823e-01, -3.4371e-01, -1.2787e-01, -4.3026e-01,\n",
       "        -5.9412e-01,  6.2290e-01,  8.8757e-01,  4.0197e-02,  8.4073e-02,\n",
       "         4.0690e-01, -2.6428e-01,  1.6700e-01, -9.4883e-03, -1.6886e-01,\n",
       "         2.0865e-01, -1.0926e-01,  1.1665e-01,  3.8245e-01,  4.7967e-02,\n",
       "        -1.1401e+00, -2.6393e-01,  1.4032e-01,  1.2306e-01, -1.1642e-01,\n",
       "        -2.0176e-01,  5.6907e-01,  6.2721e-01,  5.4071e-01, -5.6708e-02,\n",
       "        -2.8003e-01,  6.7746e-02, -4.1086e-01, -2.7354e-02,  1.0362e+00,\n",
       "         1.9268e-01,  1.6612e-01, -5.7418e-01,  1.5008e-01,  2.9581e-01,\n",
       "        -2.6740e-01, -2.6830e-01, -3.7709e-01,  1.4754e-01,  9.0948e-01,\n",
       "         2.9612e-01, -2.5388e-01, -9.3528e-02,  3.0884e-02, -1.6468e-01,\n",
       "        -2.0424e-01, -7.0724e-02,  2.3750e-01, -7.7868e-02,  5.7643e-03,\n",
       "        -7.0198e-01,  2.8018e-02,  8.0421e-02,  4.7436e-02,  1.8962e-01,\n",
       "         3.4329e-01, -3.6810e-01,  1.8884e-01, -6.3433e-02, -8.1736e-01,\n",
       "         2.4327e-01,  1.8789e-01,  8.8685e-01, -1.2024e-01, -2.4263e-01,\n",
       "         5.6385e-02,  1.9604e-01,  7.6551e-02,  1.8825e-01, -2.3370e-01,\n",
       "         1.0173e+00,  1.1965e+00, -2.3486e-01,  1.1278e+00, -1.9721e-01,\n",
       "        -5.7166e-02, -3.8694e-02, -5.4875e-01, -2.0071e-01,  6.1007e-02,\n",
       "         2.4821e-02,  9.8589e-01,  9.2868e-01,  5.5312e-01, -3.2955e-01,\n",
       "         2.2302e-01, -7.1512e-01, -1.1306e+00, -1.3584e-01,  1.7420e-02,\n",
       "        -2.0578e-02,  6.1986e-01, -1.5653e-01,  2.4203e-01, -9.2904e-01,\n",
       "        -4.5526e-01, -3.3962e-01, -4.5937e-01, -9.1684e-02,  3.7545e-03,\n",
       "         1.4230e-01, -2.6793e-01, -1.7552e-01,  1.2762e-01,  3.0295e-01,\n",
       "        -2.3969e-01, -4.0578e-01, -2.7005e-02,  5.1659e-02,  4.6264e-02,\n",
       "         3.6765e-01, -2.5533e-01,  9.9143e-02,  4.7207e-01,  2.1160e-01,\n",
       "        -1.1233e-01, -2.0147e-01, -3.5486e-01, -9.7362e-02,  6.2729e-02,\n",
       "        -1.9467e-01,  1.8432e-01,  3.3492e-01,  7.4485e-01, -2.3218e-01,\n",
       "         7.2190e-01, -2.6180e-01,  1.1969e-01,  2.9672e-01,  6.6213e-02,\n",
       "         1.4433e+00, -2.2722e-04, -1.7532e-01,  3.9760e-01, -1.0236e-01,\n",
       "        -2.9755e-01, -5.3984e-02,  3.9439e-01,  1.3301e-01, -2.0955e-02,\n",
       "         3.4239e-01,  4.0486e-02, -1.7846e-01,  3.2422e-01, -1.3443e-01,\n",
       "         8.9355e-01,  1.1154e-01,  6.0395e-02,  5.9885e-01,  1.5264e-01,\n",
       "         1.2312e-02, -7.2545e-02, -2.6267e-01, -3.7853e-01,  8.2624e-02,\n",
       "         3.8343e-01,  2.8462e-02, -4.2315e-01,  6.3219e-01, -9.6788e-02,\n",
       "        -1.6036e-01, -1.4869e+00, -9.7379e-02,  6.2626e-02,  4.9813e-01,\n",
       "         2.2401e-01, -8.8900e-02,  1.5106e-02, -8.6383e-02,  2.4490e-01,\n",
       "         6.3638e-01, -1.2091e-01,  4.5583e-01, -5.2344e-01, -3.7137e-01,\n",
       "        -5.0090e-01, -1.0336e-01,  2.1514e-01,  5.4828e-01, -1.6106e-01,\n",
       "        -3.7803e-01, -2.1918e-01,  3.3735e-01,  5.5167e-02, -2.8679e-01,\n",
       "        -3.0361e-01,  7.3065e-02,  4.5618e-01, -1.0482e-01,  5.5590e-02,\n",
       "        -2.7639e-01, -2.2940e-01, -1.7528e-01, -3.5048e-02, -1.0850e-01,\n",
       "        -2.6896e-01, -5.1492e-01, -3.9982e-01,  7.4859e-02,  8.0948e-02])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FastLM_Tamil.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
